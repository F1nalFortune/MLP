{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Functional_MLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/F1nalFortune/MLP/blob/master/Functional_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV-AzsZdpaHQ",
        "colab_type": "code",
        "outputId": "f03d195b-dc9a-48ec-88b6-fa23383c3f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from requests import get\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from random import randint\n",
        "from time import time\n",
        "from IPython.core.display import clear_output\n",
        "from warnings import warn\n",
        "import math\n",
        "import cv2\n",
        "import os\n",
        "import unicodedata\n",
        "import string\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ua0Z4UupoOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/gdrive/My Drive/test\"\n",
        "\n",
        "movie_names = open(\"{}/movie_names.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "movie_names = movie_names.read().split(\",,,\")\n",
        "\n",
        "box_office = open(\"{}/box_office.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "box_office = box_office.read().split(\",,,\")\n",
        "\n",
        "imdbRating = open(\"{}/movie_ratings.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "imdbRating = imdbRating.read().split(\",,,\")\n",
        "\n",
        "metascore = open(\"{}/metascore.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "metascore = metascore.read().split(\",,,\")\n",
        "\n",
        "movie_runtime = open(\"{}/movie_runtime.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "movie_runtime = movie_runtime.read().split(\",,,\")\n",
        "real_runtimes = []\n",
        "for runtime in movie_runtime:\n",
        "    real_runtimes.append(runtime.replace(\" min\", \"\"))\n",
        "movie_runtime = real_runtimes\n",
        "\n",
        "movieBudget = open(\"{}/movieBudget.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "movieBudget = movieBudget.read().split(\",,,\")\n",
        "\n",
        "movieCast = open(\"{}/movie_cast.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "movieCast = movieCast.read().split(\",,,\")\n",
        "\n",
        "movie_directors = open(\"{}/directors.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "movie_directors = movie_directors.read().split(\",,,\")\n",
        "\n",
        "mpaa = open(\"{}/movie_mpaa.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "mpaa = mpaa.read().split(\",,,\")\n",
        "\n",
        "genre = open(\"{}/movie_genre.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "genre = genre.read().split(\",,,\")\n",
        "\n",
        "\n",
        "release = open(\"{}/releasedate.txt\".format(path), encoding = \"ISO-8859-1\")\n",
        "release = release.read().split(\",,,\")\n",
        "\n",
        "\n",
        "# ADD DIRECTOR, CAST, MPAA, IMDB RATING\n",
        "# features = [\"box_office\", \"imdb_rating\", \"metascore\", \"movie_mpaa\", \"movie_names\", \"movie_runtime\", \"movieBudget\"]\n",
        "\n",
        "# for i, feature in range(features):\n",
        "#     name = features[i]\n",
        "#     name = open(\"{}/{}.txt\".format(path, feature))\n",
        "#     feature = feature.read().split(\",,,\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw-KlIjEp-Ox",
        "colab_type": "code",
        "outputId": "9e407eca-383c-4de1-fdf6-320ce3702515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "movie_names = movie_names[:-2001]\n",
        "print(\"Movies: {}\".format(len(movie_names)))\n",
        "\n",
        "box_office = box_office[:-2001]\n",
        "print(\"Box Office: {}\".format(len(box_office)))\n",
        "\n",
        "imdbRating = imdbRating[:-2001]\n",
        "print(\"IMDb Rating: {}\".format(len(imdbRating)))\n",
        "\n",
        "metascore = metascore[:-2001]\n",
        "print(\"Metascore: {}\".format(len(metascore)))\n",
        "\n",
        "movie_runtime = movie_runtime[:-2001]\n",
        "print(\"Runtime: {}\".format(len(movie_runtime)))\n",
        "\n",
        "movieBudget = movieBudget[:-2001]\n",
        "print(\"Budget: {}\".format(len(movieBudget)))\n",
        "\n",
        "movieCast = movieCast[:-2001]\n",
        "print(\"Movie Cast: {}\".format(len(movieCast)))\n",
        "\n",
        "movie_directors = movie_directors[:-2001]\n",
        "print(\"Movie Directors: {}\".format(len(movie_directors)))\n",
        "\n",
        "genre = genre[:-2001]\n",
        "genre_rating =[]\n",
        "for x in genre:\n",
        "    for idx, val in enumerate(set(genre)):\n",
        "        if x == val:\n",
        "            genre_rating.append(idx)\n",
        "genre = genre_rating\n",
        "print(\"Genre: {}\".format(len(genre)))\n",
        "\n",
        "mpaa = mpaa[:-2001]\n",
        "print(\"MPAA: {}\".format(len(mpaa)))\n",
        "\n",
        "release = release[:-2001]\n",
        "print(\"Release Date: {}\".format(len(release)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movies: 13000\n",
            "Box Office: 13000\n",
            "IMDb Rating: 13000\n",
            "Metascore: 13000\n",
            "Runtime: 13000\n",
            "Budget: 13000\n",
            "Movie Cast: 13000\n",
            "Movie Directors: 13000\n",
            "Genre: 13000\n",
            "MPAA: 13000\n",
            "Release Date: 13000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2kREfzFfRDW",
        "colab_type": "code",
        "outputId": "83251f14-9f13-46ed-9578-c93a99f396b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'name': movie_names,\n",
        "    'box_office': box_office,\n",
        "    'rating': imdbRating,\n",
        "    'metascore': metascore,\n",
        "    'runtime': movie_runtime,\n",
        "    'budget': movieBudget,\n",
        "    'genre': genre,\n",
        "    'mpaa':mpaa,\n",
        "    'cast':movieCast,\n",
        "    'directors':movie_directors,\n",
        "    'release':release\n",
        "})\n",
        "df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>box_office</th>\n",
              "      <th>rating</th>\n",
              "      <th>metascore</th>\n",
              "      <th>runtime</th>\n",
              "      <th>budget</th>\n",
              "      <th>genre</th>\n",
              "      <th>mpaa</th>\n",
              "      <th>cast</th>\n",
              "      <th>directors</th>\n",
              "      <th>release</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Star Wars: Episode VII - The Force Awakens</td>\n",
              "      <td>936662225</td>\n",
              "      <td>8.0</td>\n",
              "      <td>81</td>\n",
              "      <td>136</td>\n",
              "      <td>245000000</td>\n",
              "      <td>424</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Harrison Ford,Carrie Fisher,Daisy Ridley,Oscar...</td>\n",
              "      <td>J.J. Abrams</td>\n",
              "      <td>18 December 2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Avengers: Endgame</td>\n",
              "      <td>851612415</td>\n",
              "      <td>8.7</td>\n",
              "      <td>78</td>\n",
              "      <td>181</td>\n",
              "      <td>356000000</td>\n",
              "      <td>424</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Robert Downey Jr.,Mark Ruffalo,Scarlett Johans...</td>\n",
              "      <td>Anthony Russo</td>\n",
              "      <td>26 April 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Avatar</td>\n",
              "      <td>760507625</td>\n",
              "      <td>7.8</td>\n",
              "      <td>83</td>\n",
              "      <td>162</td>\n",
              "      <td>237000000</td>\n",
              "      <td>453</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Sam Worthington,Sigourney Weaver,Michelle Rodr...</td>\n",
              "      <td>James Cameron</td>\n",
              "      <td>18 December 2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Black Panther</td>\n",
              "      <td>700059566</td>\n",
              "      <td>7.3</td>\n",
              "      <td>88</td>\n",
              "      <td>134</td>\n",
              "      <td>200000000</td>\n",
              "      <td>424</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Chadwick Boseman,Lupita Nyong'o,Martin Freeman...</td>\n",
              "      <td>Ryan Coogler</td>\n",
              "      <td>16 February 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Avengers: Infinity War</td>\n",
              "      <td>678815482</td>\n",
              "      <td>8.5</td>\n",
              "      <td>68</td>\n",
              "      <td>149</td>\n",
              "      <td>321000000</td>\n",
              "      <td>424</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Robert Downey Jr.,Mark Ruffalo,Scarlett Johans...</td>\n",
              "      <td>Anthony Russo</td>\n",
              "      <td>27 April 2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         name  ...           release\n",
              "0  Star Wars: Episode VII - The Force Awakens  ...  18 December 2015\n",
              "1                           Avengers: Endgame  ...     26 April 2019\n",
              "2                                      Avatar  ...  18 December 2009\n",
              "3                               Black Panther  ...  16 February 2018\n",
              "4                      Avengers: Infinity War  ...     27 April 2018\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKO_5uJWfSlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(df[df['budget'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['runtime'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['box_office'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['metascore'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['rating'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['mpaa'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['cast'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['directors'] == 'null'].index, inplace = True) \n",
        "df.drop(df[df['release'] == 'null'].index, inplace = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1g2FrFGfT6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpaa_rating =[]\n",
        "for x in df['mpaa']:\n",
        "    for idx, val in enumerate(set(df['mpaa'])):\n",
        "        if x == val:\n",
        "            mpaa_rating.append(idx)\n",
        "new_office = []\n",
        "for value in df['box_office']:\n",
        "    new_office.append(float(value))\n",
        "    \n",
        "new_budget = []\n",
        "for value in df['budget']:\n",
        "    new_budget.append(float(value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyHqQ_2efUsn",
        "colab_type": "code",
        "outputId": "487acfc1-2a36-421b-ce35-8d3f01fd23a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"Name: {}\".format(len(df['name'])))\n",
        "print(\"BO: {}\".format(len(new_office)))\n",
        "print(\"Rating: {}\".format(len(df['rating'])))\n",
        "print(\"Meta: {}\".format(len(df['metascore'])))\n",
        "print(\"Runtime: {}\".format(len(df['runtime'])))\n",
        "print(\"Budget: {}\".format(len(df['budget'])))\n",
        "print(\"Genre: {}\".format(len(df['genre'])))\n",
        "print(\"Cast: {}\".format(len(df['cast'])))\n",
        "print(\"Directors: {}\".format(len(df['directors'])))\n",
        "print(\"Release: {}\".format(len(df['release'])))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: 5538\n",
            "BO: 5538\n",
            "Rating: 5538\n",
            "Meta: 5538\n",
            "Runtime: 5538\n",
            "Budget: 5538\n",
            "Genre: 5538\n",
            "Cast: 5538\n",
            "Directors: 5538\n",
            "Release: 5538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yGdSU2CfVXP",
        "colab_type": "code",
        "outputId": "02f36eff-2ad0-4644-cc68-f290e5f9e776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'name': df['name'],\n",
        "    'box_office': new_office,\n",
        "    'rating': df['rating'],\n",
        "    'metascore': df['metascore'],\n",
        "    'runtime': df['runtime'],\n",
        "    'budget': new_budget,\n",
        "    'genre': df['genre'],\n",
        "    'mpaa': mpaa_rating,\n",
        "    'cast':df['cast'],\n",
        "    'directors':df['directors'],\n",
        "    'release':df['release']\n",
        "})\n",
        "\n",
        "name = []\n",
        "box_office = []\n",
        "rating =[]\n",
        "runtime = []\n",
        "budget = []\n",
        "genre = []\n",
        "mpaa = []\n",
        "cast = []\n",
        "directors = []\n",
        "release = []\n",
        "metascore = []\n",
        "\n",
        "for val in df['metascore']:\n",
        "  metascore.append(val)\n",
        "for val in df['name']:\n",
        "  name.append(val)\n",
        "for val in df['box_office']:\n",
        "  box_office.append(val)\n",
        "for val in df['rating']:\n",
        "  rating.append(val)\n",
        "for val in df['runtime']:\n",
        "  runtime.append(val)\n",
        "for val in df['budget']:\n",
        "  budget.append(val)\n",
        "for val in df['genre']:\n",
        "  genre.append(val)\n",
        "for val in df['mpaa']:\n",
        "  mpaa.append(val)\n",
        "for val in df['cast']:\n",
        "  cast.append(val)\n",
        "for val in df['directors']:\n",
        "  directors.append(val)\n",
        "for val in df['release']:\n",
        "    release.append(val)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAIi04FRfYGx",
        "colab_type": "code",
        "outputId": "cd57ad16-d1c8-4df3-ab18-74a570de19ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def actor_gross(actors):\n",
        "    avg_gross_act = []\n",
        "    for actor in actors:\n",
        "        # CALCULATE TOTAL MOVIE GROSS\n",
        "#         avg_gross_act.append(df.loc[df['cast'].astype(str).str.contains(actor), 'box_office'].sum())\n",
        "        total_gross = df.loc[df['cast'].astype(str).str.contains(actor), 'box_office'].sum()\n",
        "        total_movies = len(df.loc[df['cast'].astype(str).str.contains(actor)])\n",
        "        avg_gross_act.append(total_gross/total_movies)\n",
        "    return avg_gross_act\n",
        "\n",
        "def director_gross(directors):\n",
        "    avg_gross_dir = []\n",
        "    for director in directors:\n",
        "        # CALCULATE TOTAL MOVIE GROSS\n",
        "#         avg_gross_act.append(df.loc[df['cast'].astype(str).str.contains(actor), 'box_office'].sum())\n",
        "        total_gross = df.loc[df['directors'].astype(str).str.contains(director), 'box_office'].sum()\n",
        "        total_movies = len(df.loc[df['directors'].astype(str).str.contains(director)])\n",
        "        avg_gross_dir.append(total_gross/total_movies)\n",
        "    return avg_gross_dir\n",
        "\n",
        "\n",
        "first_five = []\n",
        "for cast in df['cast']:\n",
        "    cast = cast.split(\",\")\n",
        "    top_five = cast[:5]\n",
        "    top_five = \",\".join(top_five)\n",
        "    first_five.append(top_five)\n",
        "\n",
        "actor_avg = []\n",
        "counter = 0\n",
        "for actor in first_five:\n",
        "    counter += 1\n",
        "    members = actor.split(\",\")\n",
        "    actor_avg.append(actor_gross(members))\n",
        "    if counter % 500 == 0:\n",
        "        print(counter)\n",
        "\n",
        "weighted_actors = []\n",
        "for val in actor_avg:\n",
        "    val = sum(val)/len(val)\n",
        "    val = val*.7\n",
        "    weighted_actors.append(val)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "4000\n",
            "4500\n",
            "5000\n",
            "5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVo9XQdUfYRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0e868dd0-5e2c-4b16-c8fa-7622d158423b"
      },
      "source": [
        "dir_avg = []\n",
        "for director in df['directors']:\n",
        "    counter +=1\n",
        "    members = director.split(\",\")\n",
        "    dir_avg.append(director_gross(members))\n",
        "    if counter % 500 == 0:\n",
        "        print(counter)\n",
        "\n",
        "weighted_directors = []\n",
        "for val in dir_avg:\n",
        "    val = sum(val)/len(val)\n",
        "    val = val * .3\n",
        "    weighted_directors.append(val)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "6500\n",
            "7000\n",
            "7500\n",
            "8000\n",
            "8500\n",
            "9000\n",
            "9500\n",
            "10000\n",
            "10500\n",
            "11000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMDC1rCXfYaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "star_feature = pd.DataFrame({\n",
        "    'actor': weighted_actors,\n",
        "    'director': weighted_directors,\n",
        "})\n",
        "\n",
        "star_feature['star_value'] = star_feature['actor'] + star_feature['director']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qra_nvltfYj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "months = []\n",
        "for date in df['release']:\n",
        "    if \"January\" in date:\n",
        "        months.append(\"January\")\n",
        "    elif \"February\" in date:\n",
        "        months.append(\"February\")\n",
        "    elif \"March\" in date:\n",
        "        months.append(\"March\")\n",
        "    elif \"April\" in date:\n",
        "        months.append(\"April\")\n",
        "    elif \"May\" in date:\n",
        "        months.append(\"May\")\n",
        "    elif \"June\" in date:\n",
        "        months.append(\"June\")\n",
        "    elif \"July\" in date:\n",
        "        months.append(\"July\")\n",
        "    elif \"August\" in date:\n",
        "        months.append(\"August\")\n",
        "    elif \"September\" in date:\n",
        "        months.append(\"September\")\n",
        "    elif \"October\" in date:\n",
        "        months.append(\"October\")\n",
        "    elif \"November\" in date:\n",
        "        months.append(\"November\")\n",
        "    elif \"December\" in date:\n",
        "        months.append(\"December\")\n",
        "    else:\n",
        "        months.append(\"null\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3ojj6l9fYtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_high = []\n",
        "comp_med = []\n",
        "comp_low = []\n",
        "\n",
        "for comp in months:\n",
        "    if comp in [\"January\", \"August\", \"September\", \"October\"]:\n",
        "        comp_high.append(1)\n",
        "        comp_med.append(0)\n",
        "        comp_low.append(0)\n",
        "    elif comp in [\"February\", \"March\", \"April\", \"November\", \"December\"]:\n",
        "        comp_high.append(0)\n",
        "        comp_med.append(1)\n",
        "        comp_low.append(0)\n",
        "    elif comp in [\"May\", \"June\", \"July\"]:\n",
        "        comp_high.append(0)\n",
        "        comp_med.append(0)\n",
        "        comp_low.append(1)\n",
        "    else:\n",
        "        comp_high.append('null')\n",
        "        comp_med.append('null')\n",
        "        comp_low.append('null')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpeyCzKNfY2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "808be9a4-34fe-4723-a6a2-692f3d250805"
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'name': name,\n",
        "    'box_office': box_office,\n",
        "    'rating': rating,\n",
        "    'metascore': metascore,\n",
        "    'runtime': runtime,\n",
        "    'budget': budget,\n",
        "    'genre': genre,\n",
        "    'mpaa': mpaa,\n",
        "#     'cast':cast,\n",
        "    'star_val':star_feature['star_value'],\n",
        "    'comp_high': comp_high,\n",
        "    'comp_med': comp_med,\n",
        "    'comp_low': comp_low\n",
        "})\n",
        "df.drop(df[df['comp_high'] == 'null'].index, inplace = True) \n",
        "print(len(df))\n",
        "# print(\"Name: {}\".len(df['name']))\n",
        "# print(\"Box Office: {}\".len(df['box_office']))\n",
        "# print(\"Rating: {}\".len(df['rating']))\n",
        "# print(\"Runtime: {}\".len(df['runtime']))\n",
        "# print(\"Budget: {}\".len(df['budget']))\n",
        "# print(\"Genre: {}\".len(df['genre']))\n",
        "# print(\"MPAA: {}\".len(df['mpaa']))\n",
        "# print(\"Cast: {}\".len(df['cast']))\n",
        "# print(\"Star Val: {}\".len(df['star_val']))\n",
        "df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>box_office</th>\n",
              "      <th>rating</th>\n",
              "      <th>metascore</th>\n",
              "      <th>runtime</th>\n",
              "      <th>budget</th>\n",
              "      <th>genre</th>\n",
              "      <th>mpaa</th>\n",
              "      <th>star_val</th>\n",
              "      <th>comp_high</th>\n",
              "      <th>comp_med</th>\n",
              "      <th>comp_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Star Wars: Episode VII - The Force Awakens</td>\n",
              "      <td>936662225.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>81</td>\n",
              "      <td>136</td>\n",
              "      <td>245000000.0</td>\n",
              "      <td>424</td>\n",
              "      <td>4</td>\n",
              "      <td>2.521578e+08</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Avengers: Endgame</td>\n",
              "      <td>851612415.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>78</td>\n",
              "      <td>181</td>\n",
              "      <td>356000000.0</td>\n",
              "      <td>424</td>\n",
              "      <td>4</td>\n",
              "      <td>2.174710e+08</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Avatar</td>\n",
              "      <td>760507625.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>83</td>\n",
              "      <td>162</td>\n",
              "      <td>237000000.0</td>\n",
              "      <td>453</td>\n",
              "      <td>4</td>\n",
              "      <td>1.556753e+08</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Black Panther</td>\n",
              "      <td>700059566.0</td>\n",
              "      <td>7.3</td>\n",
              "      <td>88</td>\n",
              "      <td>134</td>\n",
              "      <td>200000000.0</td>\n",
              "      <td>424</td>\n",
              "      <td>4</td>\n",
              "      <td>2.751525e+08</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Avengers: Infinity War</td>\n",
              "      <td>678815482.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>68</td>\n",
              "      <td>149</td>\n",
              "      <td>321000000.0</td>\n",
              "      <td>424</td>\n",
              "      <td>4</td>\n",
              "      <td>2.362068e+08</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         name   box_office  ... comp_med comp_low\n",
              "0  Star Wars: Episode VII - The Force Awakens  936662225.0  ...        1        0\n",
              "1                           Avengers: Endgame  851612415.0  ...        1        0\n",
              "2                                      Avatar  760507625.0  ...        1        0\n",
              "3                               Black Panther  700059566.0  ...        1        0\n",
              "4                      Avengers: Infinity War  678815482.0  ...        1        0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VgpSwD1fY__",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tehNn-eVfZ-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[[\"runtime\", \"rating\", \"budget\", \"genre\", \"mpaa\", \"metascore\", \"star_val\", \"comp_high\", \"comp_med\", \"comp_low\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuMbyCYVfiBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_regression = df['box_office']\n",
        "y_train_regression= y_train_regression.astype(np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbs1_mykfiWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1260a41c-fb07-42bb-e417-626b502c5528"
      },
      "source": [
        "X['runtime'] = X['runtime'].astype(np.float)\n",
        "X['rating'] = X['rating'].astype(np.float)\n",
        "X['budget'] = X['budget'].astype(np.float)\n",
        "X['genre'] = X['genre'].astype(np.float)\n",
        "# X['budget'] = X['budget'].astype(np.float)\n",
        "X['mpaa'] = X['mpaa'].astype(np.float)\n",
        "X['metascore'] = X['metascore'].astype(np.float)\n",
        "X['star_val'] = X['star_val'].astype(np.float)\n",
        "X['comp_high'] = X['comp_high'].astype(np.float)\n",
        "X['comp_med'] = X['comp_med'].astype(np.float)\n",
        "X['comp_low'] = X['comp_low'].astype(np.float)\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>runtime</th>\n",
              "      <th>rating</th>\n",
              "      <th>budget</th>\n",
              "      <th>genre</th>\n",
              "      <th>mpaa</th>\n",
              "      <th>metascore</th>\n",
              "      <th>star_val</th>\n",
              "      <th>comp_high</th>\n",
              "      <th>comp_med</th>\n",
              "      <th>comp_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>136.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>245000000.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>2.521578e+08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>356000000.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>2.174710e+08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>237000000.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>1.556753e+08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134.0</td>\n",
              "      <td>7.3</td>\n",
              "      <td>200000000.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.751525e+08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>149.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>321000000.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>2.362068e+08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   runtime  rating       budget  ...  comp_high  comp_med  comp_low\n",
              "0    136.0     8.0  245000000.0  ...        0.0       1.0       0.0\n",
              "1    181.0     8.7  356000000.0  ...        0.0       1.0       0.0\n",
              "2    162.0     7.8  237000000.0  ...        0.0       1.0       0.0\n",
              "3    134.0     7.3  200000000.0  ...        0.0       1.0       0.0\n",
              "4    149.0     8.5  321000000.0  ...        0.0       1.0       0.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQyCSGB9fifh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "08b85c57-ff5c-4b0b-ce73-ff4ae8858523"
      },
      "source": [
        "y_train_regression.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    936662225.0\n",
              "1    851612415.0\n",
              "2    760507625.0\n",
              "3    700059566.0\n",
              "4    678815482.0\n",
              "Name: box_office, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHlNHZjafio3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for value in y_train_regression:\n",
        "    value = float(value)\n",
        "#     print (type(value))\n",
        "    if value <= 1000000:\n",
        "        y.append(0)\n",
        "    elif value > 1000000 and value <= 10000000:\n",
        "        y.append(1)\n",
        "    elif value > 10000000 and value <= 25000000:\n",
        "        y.append(2)\n",
        "    elif value > 25000000 and value <= 50000000:\n",
        "        y.append(3)\n",
        "    elif value > 50000000 and value <= 100000000:\n",
        "        y.append(4)\n",
        "    elif value > 100000000 and value <= 200000000:\n",
        "        y.append(5)\n",
        "    elif value > 200000000 and value <= 300000000:\n",
        "        y.append(6)\n",
        "    elif value > 300000000 and value <= 400000000:\n",
        "        y.append(7)\n",
        "    elif value > 400000000 and value <= 500000000:\n",
        "        y.append(8)\n",
        "    elif value > 500000000:\n",
        "        y.append(9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BTwFGGvfixV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "X_df = X\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4NXaqt9fi6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "x_temp = scaler.transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_temp, y, test_size = 0.2, random_state = 0)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size= 0.1, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnTzvNlRfjC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyPYSPaSfjL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d368e2de-510a-4ab6-a692-c026950a95e6"
      },
      "source": [
        "x_temp[:5]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.53333775,  1.5792124 ,  5.13684133,  0.77376116,  0.77892111,\n",
              "         1.50855521,  6.42273573, -0.73044862,  1.19659441, -0.56328851],\n",
              "       [ 3.97175662,  2.27594493,  7.82954088,  0.77376116,  0.77892111,\n",
              "         1.34242337,  5.31361731, -0.73044862,  1.19659441, -0.56328851],\n",
              "       [ 2.94220199,  1.38014597,  4.94277289,  0.96192934,  0.77892111,\n",
              "         1.61930977,  3.33768648, -0.73044862,  1.19659441, -0.56328851],\n",
              "       [ 1.42496358,  0.88247987,  4.04520638,  0.77376116,  0.77892111,\n",
              "         1.89619617,  7.15799907, -0.73044862,  1.19659441, -0.56328851],\n",
              "       [ 2.23776987,  2.0768785 ,  6.98049148,  0.77376116,  0.77892111,\n",
              "         0.78865057,  5.91270061, -0.73044862,  1.19659441, -0.56328851]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmykCjaGfrUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Create tensors for our train and test set. \n",
        "As you remember we need variable to accumulate gradients. \n",
        "Therefore first we create tensor, then we will create variable '''\n",
        "# Numpy to Tensor Conversion (Train Set)\n",
        "X_train = torch.from_numpy(X_train)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "\n",
        "X_valid = torch.from_numpy(X_valid)\n",
        "y_valid = torch.from_numpy(y_valid)\n",
        "\n",
        "# Numpy to Tensor Conversion (Train Set)\n",
        "X_test = torch.from_numpy(X_test)\n",
        "y_test = torch.from_numpy(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgt3mXS5frd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38c96cb1-3dbb-4b03-f48e-e694f292b51c"
      },
      "source": [
        "set(y)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_74mdzScfrnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make torch datasets from train and test sets\n",
        "train = torch.utils.data.TensorDataset(X_train,y_train)\n",
        "valid = torch.utils.data.TensorDataset(X_valid,y_valid)\n",
        "test = torch.utils.data.TensorDataset(X_test,y_test)\n",
        "\n",
        "# Create train and test data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = 64, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size = 64, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = 64, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlaiYnrCfrv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.modules.batchnorm as bn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OnOHEg2fr4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ANN(nn.Module):\n",
        "    def __init__(self, input_dim = 10, output_dim = 10):\n",
        "        super(ANN, self).__init__()\n",
        "    \n",
        "        # Input Layer (2) -> 784\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        # 256 -> 128\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        # 128 -> 128\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        # 128 -> 64\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        # 64 -> 64\n",
        "        self.fc5 = nn.Linear(64, 64)\n",
        "        # 64 -> 32\n",
        "        self.fc6 = nn.Linear(64, 32)\n",
        "        # 32 -> 32\n",
        "        self.fc7 = nn.Linear(32, 32)\n",
        "        # 32 -> output layer(10)\n",
        "        self.output_layer = nn.Linear(32,10)\n",
        "        # Dropout Layer (20%) to reduce overfitting\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(10)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
        "    \n",
        "    # Feed Forward Function\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # csv input\n",
        "        x = x.view(-1, 10)\n",
        "        x = self.batchnorm1(x)\n",
        "        # Add ReLU activation function to each layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc6(x))\n",
        "        x = F.relu(self.fc7(x))\n",
        "        x = self.dropout(x)\n",
        "        # Don't add any ReLU activation function to Last Output Layer\n",
        "        x = self.output_layer(x)\n",
        "        \n",
        "        # Return the created model\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKUErcrifsB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "206f7481-9417-431c-c121-f6f905f0e27a"
      },
      "source": [
        "# Create the Neural Network Model\n",
        "model = ANN(input_dim = 10, output_dim = 10)\n",
        "# Print its architecture\n",
        "print(model)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANN(\n",
            "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc6): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc7): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (output_layer): Linear(in_features=32, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (batchnorm1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwhyjI7MfsK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "# specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU5hJeQJfjU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e84f2db8-dbdd-4021-9fa2-ef2065c06050"
      },
      "source": [
        "# Define epochs (between 20-50)\n",
        "epochs = 301\n",
        "\n",
        "# initialize tracker for minimum validation loss\n",
        "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "# Some lists to keep track of loss and accuracy during each epoch\n",
        "epoch_list = []\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "train_acc_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "# Start epochs\n",
        "for epoch in range(epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    # Set the training mode ON -> Activate Dropout Layers\n",
        "    model.train() # prepare model for training\n",
        "    # Calculate Accuracy         \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # Load Train Images with Labels(Targets)\n",
        "    for data, target in train_loader:\n",
        "        \n",
        "        # Convert our feature and labels to Variables to accumulate Gradients\n",
        "        data = Variable(data).float()\n",
        "        target = Variable(target).type(torch.LongTensor)\n",
        "        \n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        \n",
        "        # Calculate Training Accuracy \n",
        "        predicted = torch.max(output.data, 1)[1]        \n",
        "        # Total number of labels\n",
        "        total += len(target)\n",
        "        # Total correct predictions\n",
        "        correct += (predicted == target).sum()\n",
        "        \n",
        "        # calculate the loss\n",
        "        loss = loss_fn(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average training loss over an epoch\n",
        "    train_loss = np.mean(train_loss)\n",
        "    \n",
        "    # Avg Accuracy\n",
        "    accuracy = 100 * correct / float(total)\n",
        "    \n",
        "    # Put them in their list\n",
        "    train_acc_list.append(accuracy)\n",
        "    train_loss_list.append(train_loss)\n",
        "    \n",
        "        \n",
        "    # Implement Validation like K-fold Cross-validation \n",
        "    # Set Evaluation Mode ON -> Turn Off Dropout\n",
        "    model.eval() # Required for Evaluation/Test\n",
        "\n",
        "    # Calculate Test/Validation Accuracy         \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "\n",
        "            # Convert our images and labels to Variables to accumulate Gradients\n",
        "            data = Variable(data).float()\n",
        "            target = Variable(target).type(torch.LongTensor)\n",
        "\n",
        "            # Predict Output\n",
        "            output = model(data)\n",
        "\n",
        "            # Calculate Loss\n",
        "            loss = loss_fn(output, target)\n",
        "            val_loss += loss.item()*data.size(0)\n",
        "            # Get predictions from the maximum value\n",
        "            predicted = torch.max(output.data, 1)[1]\n",
        "\n",
        "            # Total number of labels\n",
        "            total += len(target)\n",
        "\n",
        "            # Total correct predictions\n",
        "            correct += (predicted == target).sum()\n",
        "    \n",
        "    # calculate average training loss and accuracy over an epoch\n",
        "    val_loss = np.mean(val_loss)\n",
        "    accuracy = 100 * correct/ float(total)\n",
        "    \n",
        "    # Put them in their list\n",
        "    val_acc_list.append(accuracy)\n",
        "    val_loss_list.append(val_loss)\n",
        "    if epoch % 50 == 0:\n",
        "        # Print the Epoch and Training Loss Details with Validation Accuracy   \n",
        "        print('Epoch: {} \\tTraining Loss: {:.4f}\\t Val. acc: {:.2f}%'.format(\n",
        "            epoch+1, \n",
        "            train_loss,\n",
        "            accuracy\n",
        "            ))\n",
        "        # save model if validation loss has decreased\n",
        "        if val_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            val_loss))\n",
        "            torch.save(model.state_dict(), 'model.pt')\n",
        "            valid_loss_min = val_loss\n",
        "        # Move to next epoch\n",
        "        epoch_list.append(epoch + 1)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 4790.4017\t Val. acc: 43.00%\n",
            "Validation loss decreased (inf --> 609.259868).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 4521.7304\t Val. acc: 44.00%\n",
            "Epoch: 101 \tTraining Loss: 4178.4121\t Val. acc: 45.00%\n",
            "Epoch: 151 \tTraining Loss: 4071.9272\t Val. acc: 38.00%\n",
            "Epoch: 201 \tTraining Loss: 3790.1417\t Val. acc: 43.00%\n",
            "Epoch: 251 \tTraining Loss: 3715.2351\t Val. acc: 37.00%\n",
            "Epoch: 301 \tTraining Loss: 3425.8390\t Val. acc: 42.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXIq8bJdcXBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ead2d127-f3bb-4a3a-bbcc-fda0d56b5941"
      },
      "source": [
        "test_loss = 0\n",
        "accuracy_test = 0\n",
        "test_total = 0\n",
        "correct = 0\n",
        "for data, target in test_loader:\n",
        "  # Convert our images and labels to Variables to accumulate Gradients\n",
        "  data = Variable(data).float()\n",
        "  target = Variable(target).type(torch.LongTensor)\n",
        "\n",
        "  # Predict Output\n",
        "  output = model(data)\n",
        "\n",
        "  # Calculate Loss\n",
        "  loss = loss_fn(output, target)\n",
        "  test_loss += loss.item()*data.size(0)\n",
        "  # Get predictions from the maximum value\n",
        "  predicted = torch.max(output.data, 1)[1]\n",
        "\n",
        "  # Total number of labels\n",
        "  test_total += len(target)\n",
        "\n",
        "  # Total correct predictions\n",
        "  correct += (predicted == target).sum()\n",
        " \n",
        "test_loss = np.mean(test_loss)\n",
        "accuracy_test = 100 * correct/ float(test_total)\n",
        "print('Test loss', test_loss)\n",
        "print('Test Accuracy', accuracy_test)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss 2357.7726588249207\n",
            "Test Accuracy tensor(35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aQf22tsfjeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.load(\"model.pt\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgSyH3b3f4RQ",
        "colab_type": "text"
      },
      "source": [
        "**Kfold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_fwn5Vwf1vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7b5cc3e8-62dc-47ad-9216-93367eb586ee"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "x_temp = scaler.transform(X)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(x_temp, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kfolds = KFold(5, False).split(x_temp)\n",
        "for _, (X_index, y_index) in enumerate(kfolds):\n",
        "    '''Create tensors for our train and test set. \n",
        "    As you remember we need variable to accumulate gradients. \n",
        "    Therefore first we create tensor, then we will create variable '''\n",
        "    X_train = X[X_index]\n",
        "    y_train = y[X_index]\n",
        "    X_test = X[y_index]\n",
        "    y_test = y[y_index]\n",
        "    X_train = torch.from_numpy(X_train)\n",
        "    y_train = torch.from_numpy(y_train)\n",
        "\n",
        "    # Numpy to Tensor Conversion (Train Set)\n",
        "    X_test = torch.from_numpy(X_test)\n",
        "    y_test = torch.from_numpy(y_test)\n",
        "    # Make torch datasets from train and test sets\n",
        "    train = torch.utils.data.TensorDataset(X_train,y_train)\n",
        "    test = torch.utils.data.TensorDataset(X_test,y_test)\n",
        "\n",
        "    # Create train and test data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size = 64, shuffle = True)\n",
        "    test_loader = torch.utils.data.DataLoader(test, batch_size = 64, shuffle = True)\n",
        "    # Define 1epochs (between 20-50)\n",
        "    epochs = 51\n",
        "\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "    # Some lists to keep track of loss and accuracy during each epoch\n",
        "    epoch_list = []\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "\n",
        "    # Start epochs\n",
        "    for epoch in range(epochs):\n",
        "        # monitor training loss\n",
        "        train_loss = 0.0\n",
        "        val_loss = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        # Set the training mode ON -> Activate Dropout Layers\n",
        "        model.train() # prepare model for training\n",
        "        # Calculate Accuracy         \n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Load Train Images with Labels(Targets)\n",
        "        for data, target in train_loader:\n",
        "\n",
        "            # Convert our feature and labels to Variables to accumulate Gradients\n",
        "            data = Variable(data).float()\n",
        "            target = Variable(target).type(torch.LongTensor)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "\n",
        "            # Calculate Training Accuracy \n",
        "            predicted = torch.max(output.data, 1)[1]        \n",
        "            # Total number of labels\n",
        "            total += len(target)\n",
        "            # Total correct predictions\n",
        "            correct += (predicted == target).sum()\n",
        "\n",
        "            # calculate the loss\n",
        "            loss = loss_fn(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update running training loss\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "\n",
        "        # calculate average training loss over an epoch\n",
        "        train_loss = np.mean(train_loss)\n",
        "\n",
        "        # Avg Accuracy\n",
        "        accuracy = 100 * correct / float(total)\n",
        "\n",
        "        # Put them in their list\n",
        "        train_acc_list.append(accuracy)\n",
        "        train_loss_list.append(train_loss)\n",
        "\n",
        "\n",
        "        # Implement Validation like K-fold Cross-validation \n",
        "        # Set Evaluation Mode ON -> Turn Off Dropout\n",
        "        model.eval() # Required for Evaluation/Test\n",
        "\n",
        "        # Calculate Test/Validation Accuracy         \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "\n",
        "                # Convert our images and labels to Variables to accumulate Gradients\n",
        "                data = Variable(data).float()\n",
        "                target = Variable(target).type(torch.LongTensor)\n",
        "\n",
        "                # Predict Output\n",
        "                output = model(data)\n",
        "\n",
        "                # Calculate Loss\n",
        "                loss = loss_fn(output, target)\n",
        "                val_loss += loss.item()*data.size(0)\n",
        "                # Get predictions from the maximum value\n",
        "                predicted = torch.max(output.data, 1)[1]\n",
        "\n",
        "                # Total number of labels\n",
        "                total += len(target)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == target).sum()\n",
        "\n",
        "        # calculate average training loss and accuracy over an epoch\n",
        "        val_loss = np.mean(val_loss)\n",
        "        accuracy = 100 * correct/ float(total)\n",
        "\n",
        "        # Put them in their list\n",
        "        val_acc_list.append(accuracy)\n",
        "        val_loss_list.append(val_loss)\n",
        "        if epoch % 50 == 0:\n",
        "            # Print the Epoch and Training Loss Details with Validation Accuracy   \n",
        "            print('Epoch: {} \\tTraining Loss: {:.4f}\\t Val. acc: {:.2f}%'.format(\n",
        "                epoch+1, \n",
        "                train_loss,\n",
        "                accuracy\n",
        "                ))\n",
        "            # save model if validation loss has decreased\n",
        "            if val_loss <= valid_loss_min:\n",
        "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_loss_min,\n",
        "                val_loss))\n",
        "                torch.save(model.state_dict(), 'model.pt')\n",
        "                valid_loss_min = val_loss\n",
        "            # Move to next epoch\n",
        "            epoch_list.append(epoch + 1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 5589.3026\t Val. acc: 12.00%\n",
            "Validation loss decreased (inf --> 5208.806944).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 4757.6935\t Val. acc: 12.00%\n",
            "Epoch: 1 \tTraining Loss: 6571.0759\t Val. acc: 38.00%\n",
            "Validation loss decreased (inf --> 1528.085767).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 4804.0200\t Val. acc: 22.00%\n",
            "Epoch: 1 \tTraining Loss: 5166.5915\t Val. acc: 23.00%\n",
            "Validation loss decreased (inf --> 1525.497304).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 4500.5476\t Val. acc: 15.00%\n",
            "Epoch: 1 \tTraining Loss: 5066.0885\t Val. acc: 21.00%\n",
            "Validation loss decreased (inf --> 1597.012022).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 4148.9690\t Val. acc: 16.00%\n",
            "Epoch: 1 \tTraining Loss: 5251.9981\t Val. acc: 13.00%\n",
            "Validation loss decreased (inf --> 4002.060051).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 4322.4578\t Val. acc: 13.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq33me1Qf14u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJKKn4gmf2Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIp4emT2f2Ka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0414768f-1871-4e2c-e272-1283ddcc3839"
      },
      "source": [
        "clf.fit(x_temp, y)  "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsGZyennf2TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "importances = clf.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjzp0J14gBGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "1c0371d5-1334-4c6a-97a3-fbfc2173c6ad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "(pd.Series(clf.feature_importances_, index=X_df.columns)\n",
        "   .nlargest(5)\n",
        "   .plot(kind='barh'))  "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa985667908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD8CAYAAABDwhLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riO9GOTugBPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8v15GGEgBYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}